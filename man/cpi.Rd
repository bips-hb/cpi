% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/cpi.R
\name{cpi}
\alias{cpi}
\title{Conditional Predictive Impact (CPI). A general test for conditional 
independence in supervised learning algorithms. Implements a conditional 
variable importance measure which can be applied to any supervised learning 
algorithm and loss function. Provides statistical inference procedures 
without parametric assumptions and applies equally well to continuous and 
categorical predictors and outcomes.}
\usage{
cpi(
  task,
  learner,
  resampling = NULL,
  test_data = NULL,
  measure = NULL,
  test = "t",
  log = FALSE,
  B = 1999,
  alpha = 0.05,
  x_tilde = NULL,
  verbose = FALSE,
  cores = 1
)
}
\arguments{
\item{task}{The prediction \code{mlr} task, see examples.}

\item{learner}{The \code{mlr} learner used in CPI. If you pass a string, the 
learner will be created via \link{makeLearner}.}

\item{resampling}{Resampling description object, mlr resampling strategy 
(e.g. \code{makeResampleDesc("Holdout")}), "oob" (out-of-bag) or "none" 
(in-sample loss).}

\item{test_data}{External validation data, use instead of resampling.}

\item{measure}{Performance measure (loss). Per default, use MSE for 
regression and logloss for classification.}

\item{test}{Statistical test to perform, one of \code{"t"} (t-test, default), 
\code{"wilcox"} (Wilcoxon signed-rank test), \code{"binom"} (binomial 
test), \code{"fisher"} (Fisher permutation test) or "bayes" 
(Bayesian testing, computationally intensive!). See Details.}

\item{log}{Set to \code{TRUE} for multiplicative CPI (\eqn{\lambda}), to 
\code{FALSE} (default) for additive CPI (\eqn{\Delta}).}

\item{B}{Number of permutations for Fisher permutation test.}

\item{alpha}{Significance level for confidence intervals.}

\item{x_tilde}{Knockoff matrix. If not given (the default), it will be 
created with \link{create.second_order}.}

\item{verbose}{Verbose output of resampling procedure.}

\item{cores}{Number of CPU cores used.}
}
\value{
For \code{test = "bayes"} a list of \code{BEST} objects. In any other 
case, a \code{data.frame} with a row for each feature and columns:
  \item{Variable}{Variable name}
  \item{CPI}{CPI value}
  \item{SE}{Standard error}
  \item{test}{Testing method}
  \item{statistic}{Test statistic (only for t-test)}
  \item{p.value}{p-value}
  \item{estimate}{Estimated mean (for t-test), median (for Wilcoxon test),
    or proportion of \eqn{\Delta}-values greater than 0 (for binomial test).}
  \item{ci.lo}{Lower limit of (1 - \code{alpha}) * 100\% confidence interval}
}
\description{
Conditional Predictive Impact (CPI). A general test for conditional 
independence in supervised learning algorithms. Implements a conditional 
variable importance measure which can be applied to any supervised learning 
algorithm and loss function. Provides statistical inference procedures 
without parametric assumptions and applies equally well to continuous and 
categorical predictors and outcomes.
}
\details{
This function computes the conditional predictive impact (CPI) of one or
several features on a given supervised learning task. This represents the 
mean error inflation when replacing a true variable with its knockoff. Large
CPI values are evidence that the feature(s) in question have high 
\emph{conditional variable importance} -- i.e., the fitted model relies on 
the feature(s) to predict the outcome, even after accounting for the signal
from all remaining covariates. 

We build on the \code{mlr} framework, which provides a unified interface for 
training models, specifying loss functions, and estimating generalization 
error. See the package documentation for more info.

Methods are implemented for frequentist and Bayesian inference. The default
is \code{test = "t"}, which is fast and powerful for most sample sizes. The
Wilcoxon signed-rank test may be more appropriate if the CPI distribution is 
skewed, while the binomial test requires basically no assumptions but may
have less power. For small sample sizes, we recommend permutation tests 
(\code{test = "fisher"}) or Bayesian methods (\code{test = "bayes"}). In
the latter case, default priors are assumed. See the \code{BEST} package for
more info.
}
\examples{
library(mlr)
# Regression with linear model
bh.task.num <- dropFeatures(bh.task, "chas")
cpi(task = bh.task.num, learner = makeLearner("regr.lm"), 
    resampling = makeResampleDesc("Holdout"))

# Classification with logistic regression, log-loss and subsampling
cpi(task = iris.task, 
    learner = makeLearner("classif.glmnet", predict.type = "prob"), 
    resampling = makeResampleDesc("CV", iters = 5), 
    measure = "logloss", test = "t")
 
# Use your own data
mytask <- makeClassifTask(data = iris, target = "Species")
mylearner <- makeLearner("classif.ranger")
cpi(task = mytask, learner = mylearner, 
    resampling = makeResampleDesc("Subsample", iters = 5), 
    measure = "mmce", test = "fisher")
    
\dontrun{
# Bayesian testing
res <- cpi(task = iris.task, 
           learner = makeLearner("classif.glmnet", predict.type = "prob"), 
           resampling = makeResampleDesc("Holdout"), 
           measure = "logloss", test = "bayes")
plot(res$Petal.Length)
}   

}
\references{
Watson, D. & Wright, M. (2020). Testing conditional independence in 
supervised learning algorithms. \emph{Machine Learning}, \emph{110}(8): 
2107-2129. \doi{10.1007/s10994-021-06030-6}

CandÃ¨s, E., Fan, Y., Janson, L, & Lv, J. (2018). {Panning for gold: 'model-X'
knockoffs for high dimensional controlled variable selection}. \emph{J. R. 
Statistc. Soc. B}, \emph{80}(3): 551-577. \doi{10.1111/rssb.12265}
}
